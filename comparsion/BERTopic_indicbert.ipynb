{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get processed data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/\"\n",
    "\n",
    "data = pd.read_csv(file_path+\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "\n",
    "df=data[\"news_title\"]\n",
    "\n",
    "docs = [str(i) for i in df.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samyuktha/opt/anaconda3/envs/ml/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertModel: ['predictions.decoder.weight', 'predictions.bias', 'predictions.dense.bias', 'sop_classifier.classifier.bias', 'sop_classifier.classifier.weight', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1250 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|██████████| 1250/1250 [01:23<00:00, 15.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use model to convert words to vectors - EMBEDDING STEP\n",
    "\n",
    "import transformers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "\n",
    "model_name = \"ai4bharat/indic-bert\"\n",
    "\n",
    "# Use tokenizer to separate words\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, keep_accents=True)\n",
    "\n",
    "\n",
    "model = transformers.AutoModel.from_pretrained(model_name)\n",
    "\n",
    "n = len(data)\n",
    "batch_size = 8\n",
    "\n",
    "embeds = torch.zeros((n, model.config.hidden_size))\n",
    "\n",
    "docs = [str(i) for i in data[\"news_title\"].values]\n",
    "\n",
    "for i in tqdm(range(0, n, batch_size)):\n",
    "    i_end = min(i+batch_size, n)\n",
    "    batch = docs[i:i_end]\n",
    "    batch_encoded = tokenizer.batch_encode_plus(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    batch_inputs = {'input_ids': batch_encoded['input_ids'], 'attention_mask': batch_encoded['attention_mask']}\n",
    "    batch_outputs = model(**batch_inputs)\n",
    "    with torch.no_grad():\n",
    "        batch_embed = batch_outputs.last_hidden_state[:, 0, :]\n",
    "    embeds[i:i_end,:] = batch_embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize docs trivially (split on spaces)\n",
    "\n",
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
    "\n",
    "def tokenize_ta(text,return_tensors=\"pt\",*args,**kwargs):\n",
    "    return indic_tokenize.trivial_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common list of stopwords\n",
    "\n",
    "stopwords=['அங்கு',\n",
    " 'அங்கே',\n",
    " 'அடுத்த',\n",
    " 'அதனால்',\n",
    " 'அதன்',\n",
    " 'அதற்கு',\n",
    " 'அதிக',\n",
    " 'அதில்',\n",
    " 'அது',\n",
    " 'அதே',\n",
    " 'அதை',\n",
    " 'அந்த',\n",
    " 'அந்தக்',\n",
    " 'அந்தப்',\n",
    " 'அன்று',\n",
    " 'அல்லது',\n",
    " 'அவன்',\n",
    " 'அவரது',\n",
    " 'அவர்',\n",
    " 'அவர்கள்',\n",
    " 'அவள்',\n",
    " 'அவை',\n",
    " 'ஆகிய',\n",
    " 'ஆகியோர்',\n",
    " 'ஆகும்',\n",
    " 'இங்கு',\n",
    " 'இங்கே',\n",
    " 'இடத்தில்',\n",
    " 'இடம்',\n",
    " 'இதனால்',\n",
    " 'இதனை',\n",
    " 'இதன்',\n",
    " 'இதற்கு',\n",
    " 'இதில்',\n",
    " 'இது',\n",
    " 'இதை',\n",
    " 'இந்த',\n",
    " 'இந்தக்',\n",
    " 'இந்தத்',\n",
    " 'இந்தப்',\n",
    " 'இன்னும்',\n",
    " 'இப்போது',\n",
    " 'இரு',\n",
    " 'இருக்கும்',\n",
    " 'இருந்த',\n",
    " 'இருந்தது',\n",
    " 'இருந்து',\n",
    " 'இவர்',\n",
    " 'இவை',\n",
    " 'உன்',\n",
    " 'உள்ள',\n",
    " 'உள்ளது',\n",
    " 'உள்ளன',\n",
    " 'எந்த',\n",
    " 'என',\n",
    " 'எனக்',\n",
    " 'எனக்கு',\n",
    " 'எனப்படும்',\n",
    " 'எனவும்',\n",
    " 'எனவே',\n",
    " 'எனினும்',\n",
    " 'எனும்',\n",
    " 'என்',\n",
    " 'என்ன',\n",
    " 'என்னும்',\n",
    " 'என்பது',\n",
    " 'என்பதை',\n",
    " 'என்ற',\n",
    " 'என்று',\n",
    " 'என்றும்',\n",
    " 'எல்லாம்',\n",
    " 'ஏன்',\n",
    " 'ஒரு',\n",
    " 'ஒரே',\n",
    " 'ஓர்',\n",
    " 'கொண்ட',\n",
    " 'கொண்டு',\n",
    " 'கொள்ள',\n",
    " 'சற்று',\n",
    " 'சிறு',\n",
    " 'சில',\n",
    " 'சேர்ந்த',\n",
    " 'தனது',\n",
    " 'தன்',\n",
    " 'தவிர',\n",
    " 'தான்',\n",
    " 'நான்',\n",
    " 'நாம்',\n",
    " 'நீ',\n",
    " 'பற்றி',\n",
    " 'பற்றிய',\n",
    " 'பல',\n",
    " 'பலரும்',\n",
    " 'பல்வேறு',\n",
    " 'பின்',\n",
    " 'பின்னர்',\n",
    " 'பிற',\n",
    " 'பிறகு',\n",
    " 'பெரும்',\n",
    " 'பேர்',\n",
    " 'போது',\n",
    " 'போன்ற',\n",
    " 'போல',\n",
    " 'போல்',\n",
    " 'மட்டுமே',\n",
    " 'மட்டும்',\n",
    " 'மற்ற',\n",
    " 'மற்றும்',\n",
    " 'மிக',\n",
    " 'மிகவும்',\n",
    " 'மீது',\n",
    " 'முதல்',\n",
    " 'முறை',\n",
    " 'மேலும்',\n",
    " 'மேல்',\n",
    " 'யார்',\n",
    " 'வந்த',\n",
    " 'வந்து',\n",
    " 'வரும்',\n",
    " 'வரை',\n",
    " 'வரையில்',\n",
    " 'விட',\n",
    " 'விட்டு',\n",
    " 'வேண்டும்',\n",
    " 'வேறு']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a vectorizer object to generate term document counts for topic representation - TOKENIZATION STEP\n",
    "\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=stopwords,analyzer='word',\n",
    "    tokenizer=tokenize_ta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a BERTopic model\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    verbose=True,\n",
    "    calculate_probabilities=False,\n",
    "    embedding_model=model,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "2023-04-23 16:01:51,632 - BERTopic - Reduced dimensionality\n",
      "2023-04-23 16:01:51,802 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the documents\n",
    "\n",
    "embeds_np = embeds.detach().numpy()\n",
    "\n",
    "topics = topic_model.fit_transform(docs,embeds_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Preprocess documents\n",
    "\n",
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "\n",
    "# Extract vectorizer and tokenizer from BERTopic\n",
    "\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tokens = [tokenizer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(topic_model.get_topics())-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.49282077\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Load pre-trained Word2Vec model for Tamil language\n",
    "\n",
    "model_path = \"/Users/samyuktha/FYP/data/cc.ta.300.vec.gz\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(model_path)\n",
    "\n",
    "# Compute coherence score using Word2Vec similarity measure\n",
    "\n",
    "cm = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "coherence='c_w2v',keyed_vectors=w2v_model)\n",
    "\n",
    "coherence_score = cm.get_coherence()\n",
    "\n",
    "print(\"Coherence Score:\", coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "coherences=['u_mass', 'c_v', 'c_uci', 'c_npmi']\n",
    "scores=[]\n",
    "for coherence in coherences:\n",
    "    cm = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary,\n",
    "                                    coherence=coherence)\n",
    "    coherence_score = cm.get_coherence()\n",
    "    scores.append(coherence_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_mass -17.456009741200674\n",
      "c_v 0.3858563562981296\n",
      "c_uci -9.496053831994537\n",
      "c_npmi -0.29164942649079845\n"
     ]
    }
   ],
   "source": [
    "#print scores\n",
    "\n",
    "for i in range(len(coherences)):\n",
    "    print(coherences[i],scores[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
