{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get processed data\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_path = \"../data/\"\n",
    "\n",
    "data = pd.read_csv(file_path+\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "df=data[\"news_title\"]\n",
    "\n",
    "docs = [str(i) for i in df.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpemb\n",
    "from bpemb import BPEmb\n",
    "import numpy as np\n",
    "\n",
    "# Load BPEmb model for Tamil\n",
    "model = BPEmb(lang=\"ta\", dim=300, vs=200000)\n",
    "\n",
    "# Generate embeddings for news_title column\n",
    "embeds = []\n",
    "for title in docs:\n",
    "    embed = model.embed(title)\n",
    "    embeds.append(np.mean(embed, axis=0))\n",
    "\n",
    "embeds = np.array(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize docs trivially (split on spaces)\n",
    "\n",
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
    "\n",
    "def tokenize_ta(text,return_tensors=\"pt\",*args,**kwargs):\n",
    "    return indic_tokenize.trivial_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common list of stopwords\n",
    "\n",
    "stopwords=['அங்கு',\n",
    " 'அங்கே',\n",
    " 'அடுத்த',\n",
    " 'அதனால்',\n",
    " 'அதன்',\n",
    " 'அதற்கு',\n",
    " 'அதிக',\n",
    " 'அதில்',\n",
    " 'அது',\n",
    " 'அதே',\n",
    " 'அதை',\n",
    " 'அந்த',\n",
    " 'அந்தக்',\n",
    " 'அந்தப்',\n",
    " 'அன்று',\n",
    " 'அல்லது',\n",
    " 'அவன்',\n",
    " 'அவரது',\n",
    " 'அவர்',\n",
    " 'அவர்கள்',\n",
    " 'அவள்',\n",
    " 'அவை',\n",
    " 'ஆகிய',\n",
    " 'ஆகியோர்',\n",
    " 'ஆகும்',\n",
    " 'இங்கு',\n",
    " 'இங்கே',\n",
    " 'இடத்தில்',\n",
    " 'இடம்',\n",
    " 'இதனால்',\n",
    " 'இதனை',\n",
    " 'இதன்',\n",
    " 'இதற்கு',\n",
    " 'இதில்',\n",
    " 'இது',\n",
    " 'இதை',\n",
    " 'இந்த',\n",
    " 'இந்தக்',\n",
    " 'இந்தத்',\n",
    " 'இந்தப்',\n",
    " 'இன்னும்',\n",
    " 'இப்போது',\n",
    " 'இரு',\n",
    " 'இருக்கும்',\n",
    " 'இருந்த',\n",
    " 'இருந்தது',\n",
    " 'இருந்து',\n",
    " 'இவர்',\n",
    " 'இவை',\n",
    " 'உன்',\n",
    " 'உள்ள',\n",
    " 'உள்ளது',\n",
    " 'உள்ளன',\n",
    " 'எந்த',\n",
    " 'என',\n",
    " 'எனக்',\n",
    " 'எனக்கு',\n",
    " 'எனப்படும்',\n",
    " 'எனவும்',\n",
    " 'எனவே',\n",
    " 'எனினும்',\n",
    " 'எனும்',\n",
    " 'என்',\n",
    " 'என்ன',\n",
    " 'என்னும்',\n",
    " 'என்பது',\n",
    " 'என்பதை',\n",
    " 'என்ற',\n",
    " 'என்று',\n",
    " 'என்றும்',\n",
    " 'எல்லாம்',\n",
    " 'ஏன்',\n",
    " 'ஒரு',\n",
    " 'ஒரே',\n",
    " 'ஓர்',\n",
    " 'கொண்ட',\n",
    " 'கொண்டு',\n",
    " 'கொள்ள',\n",
    " 'சற்று',\n",
    " 'சிறு',\n",
    " 'சில',\n",
    " 'சேர்ந்த',\n",
    " 'தனது',\n",
    " 'தன்',\n",
    " 'தவிர',\n",
    " 'தான்',\n",
    " 'நான்',\n",
    " 'நாம்',\n",
    " 'நீ',\n",
    " 'பற்றி',\n",
    " 'பற்றிய',\n",
    " 'பல',\n",
    " 'பலரும்',\n",
    " 'பல்வேறு',\n",
    " 'பின்',\n",
    " 'பின்னர்',\n",
    " 'பிற',\n",
    " 'பிறகு',\n",
    " 'பெரும்',\n",
    " 'பேர்',\n",
    " 'போது',\n",
    " 'போன்ற',\n",
    " 'போல',\n",
    " 'போல்',\n",
    " 'மட்டுமே',\n",
    " 'மட்டும்',\n",
    " 'மற்ற',\n",
    " 'மற்றும்',\n",
    " 'மிக',\n",
    " 'மிகவும்',\n",
    " 'மீது',\n",
    " 'முதல்',\n",
    " 'முறை',\n",
    " 'மேலும்',\n",
    " 'மேல்',\n",
    " 'யார்',\n",
    " 'வந்த',\n",
    " 'வந்து',\n",
    " 'வரும்',\n",
    " 'வரை',\n",
    " 'வரையில்',\n",
    " 'விட',\n",
    " 'விட்டு',\n",
    " 'வேண்டும்',\n",
    " 'வேறு']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a vectorizer object to generate term document counts for topic representation - TOKENIZATION STEP\n",
    "\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=stopwords,analyzer='word',\n",
    "    tokenizer=tokenize_ta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a BERTopic model\n",
    "\n",
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    verbose=True,\n",
    "    calculate_probabilities=False,\n",
    "    embedding_model=model,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "2023-04-19 21:50:02,401 - BERTopic - Reduced dimensionality\n",
      "2023-04-19 21:50:02,643 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the documents\n",
    "embeds_np = embeds\n",
    "\n",
    "topics = topic_model.fit_transform(docs,embeds_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Preprocess documents\n",
    "\n",
    "cleaned_docs = topic_model._preprocess_text(docs)\n",
    "\n",
    "# Extract vectorizer and tokenizer from BERTopic\n",
    "\n",
    "vectorizer = topic_model.vectorizer_model\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# Extract features for Topic Coherence evaluation\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "tokens = [tokenizer(doc) for doc in cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = [dictionary.doc2bow(token) for token in tokens]\n",
    "topic_words = [[words for words, _ in topic_model.get_topic(topic)] \n",
    "               for topic in range(len(topic_model.get_topics())-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.56090033\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Load pre-trained Word2Vec model for Tamil language\n",
    "model_path = \"/Users/samyuktha/FYP/data/cc.ta.300.vec.gz\"\n",
    "w2v_model = KeyedVectors.load_word2vec_format(model_path)\n",
    "\n",
    "# Compute coherence score using Word2Vec similarity measure\n",
    "\n",
    "cm = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary, \n",
    "coherence='c_w2v',keyed_vectors=w2v_model)\n",
    "\n",
    "coherence_score = cm.get_coherence()\n",
    "\n",
    "print(\"Coherence Score:\", coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "coherences=['u_mass', 'c_v', 'c_uci', 'c_npmi']\n",
    "scores=[]\n",
    "for coherence in coherences:\n",
    "    cm = CoherenceModel(topics=topic_words, \n",
    "                                 texts=tokens, \n",
    "                                 corpus=corpus,\n",
    "                                 dictionary=dictionary,\n",
    "                                    coherence=coherence)\n",
    "    coherence_score = cm.get_coherence()\n",
    "    scores.append(coherence_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_mass -12.381233306653847\n",
      "c_v 0.39565454703295444\n",
      "c_uci -5.038463922413552\n",
      "c_npmi -0.023719545677696425\n"
     ]
    }
   ],
   "source": [
    "#print scores\n",
    "\n",
    "for i in range(len(coherences)):\n",
    "    print(coherences[i],scores[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
